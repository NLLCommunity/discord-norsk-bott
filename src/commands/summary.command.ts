import { Injectable, Logger } from '@nestjs/common';
import { Command, Handler, InteractionEvent } from '@discord-nestjs/core';
import { SlashCommandPipe } from '@discord-nestjs/common';
import {
  ChannelType,
  Collection,
  Message,
  PermissionFlagsBits,
  type ChatInputCommandInteraction,
} from 'discord.js';
import { OpenAiProvider } from '../providers/index.js';

export class SummarizeCommandParams {}

/**
 * Summarizes the past messages in the current thread.
 */
@Injectable()
@Command({
  name: 'summary',
  description: 'Summarizes the past messages in the current thread.',
  defaultMemberPermissions: PermissionFlagsBits.SendMessages,
})
export class SummarizeCommand {
  constructor(private readonly openai: OpenAiProvider) {}

  #logger = new Logger(SummarizeCommand.name);

  /**
   * Handles the command.
   * @param interaction The interaction event.
   * @param params The command parameters.
   */
  @Handler()
  async handle(
    @InteractionEvent() interaction: ChatInputCommandInteraction,
    @InteractionEvent(SlashCommandPipe)
    {}: SummarizeCommandParams,
  ): Promise<void> {
    this.#logger.log(`Summarizing past messages in the current thread`);

    if (!this.openai.isAvailable) {
      await interaction.reply({
        content:
          'This command is not available because it has not been configured.',
        ephemeral: true,
      });

      return;
    }

    // Make sure the current channel is a thread
    if (
      !interaction.channel?.isThread() ||
      interaction.channel.parent?.type !== ChannelType.GuildForum
    ) {
      await interaction.reply({
        content: 'This command can only be used in a thread in a forum.',
        ephemeral: true,
      });

      return;
    }

    await interaction.deferReply({
      ephemeral: true,
    });

    try {
      const batchSize = 100;
      let messages: Message[] = [];
      let lastMessageId: string | null | undefined =
        interaction.channel?.lastMessageId;
      let batch: Collection<string, Message>;

      do {
        batch = await interaction.channel?.messages.fetch({
          limit: batchSize,
          ...(lastMessageId ? { before: lastMessageId } : {}),
        });

        if (!batch.size) {
          break;
        }

        messages = messages.concat(batch.toJSON());
        lastMessageId = batch.last()?.id;
      } while (messages.length < 500 && lastMessageId);

      if (!messages) {
        this.#logger.warn('No messages found in the current thread');
        interaction.editReply('No messages found in the current thread');
        return;
      }

      const content = messages
        .reverse()
        .filter((message) => message.author.bot === false)
        .map(
          (message) =>
            `@${message.author.id} (${message.author.username}): ${message.content}`,
        )
        .join('\n');

      const response = await this.openai.summarize(
        content,
        `If your summary contains a user mention with a numeric user ID (e.g. @123456789...), it must be formatted as <@numericuserid>, and for channels, <#numericchannelid>. Do not surround the bracketed mentions with code backticks.
Where possible, _always_ refer to users with a mention (e.g. <@numericuserid>), not with a username. This is because usernames can change, but IDs are permanent.
Use a concise and clear writing style. Avoid using jargon or overly complex language.
Use bullet points or numbered lists to organize information.
Use bold or italic text to emphasize key points.
If people are discussing solutions for a problem or set of problems, structure the summary such that you first introduce the problem(s), and then the proposed solutions and what people's opinions are on them.`,
      );

      if (!response) {
        this.#logger.warn('Failed to summarize past messages');
        interaction.editReply('Failed to summarize past messages');
        return;
      }

      let summary = `**Summary of past messages in the current thread:**

> ⚠️ **Note:** This summary is generated by an AI model and may not be accurate or vary each time it is generated. For the most accurate information, please refer to the original messages.

`;
      let lastLength = 0;

      const interval = setInterval(() => {
        if (summary.length === lastLength) {
          return;
        }

        lastLength = summary.length;

        interaction.editReply(summary + '▮').catch((error) => {
          this.#logger.error('Failed to update summary', error);
        });
      }, 500);

      for await (const chunk of response) {
        summary += chunk.choices[0]?.delta.content ?? '';

        if (summary.length >= 2000) {
          const tooLong = '…\n\n**Summary too long, truncating here.**';

          summary = summary.slice(0, 2000 - tooLong.length) + tooLong;

          response.controller.abort();

          break;
        }
      }

      clearInterval(interval);
      await interaction.editReply(summary);
    } catch (err) {
      this.#logger.error('Failed to summarize past messages', err);
      interaction.editReply('Failed to summarize past messages');
    }
  }
}
